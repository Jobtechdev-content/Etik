# **Ethics and digital matching**

The project aims to highlight issues of ethics and sustainability related to digital matching.

**Digital matching – what could go possible wrong?**

The discussion about ethical and unethical matching in the labour market is not new, but the emergence of digital matching algorithms introduces new perspectives. For the Swedish Public Employment Service, transparency about how these new technologies can be used is valuable. This forum aims to discuss potential improvements and risks.

In the labour market, matching refers to processes in which job seekers and employers collect and evaluate information about each other in order to find a match between a job offer and potential manpower that is good enough to justify completing a recruitment.

The matching process can be carried out entirely by computers, without human intervention, by people working without digital support, or — most commonly — through a human-machine interaction. It is a common misconception that the objectivity of the process increases when more data and algorithms are used. Our starting point is that all stages of these processes can lead to unethical consequences, no matter whether they are carried out by humans or by digital solutions.

**Social bias and discrimination**

For the labour market, some of the most important data sources are job advertisements, CV data and education/training descriptions. Because discrimination occurs in society, a digital model trained using these data also risks reinforcing that discrimination.

This issue came to the fore in 2018, when it emerged that a machine learning-based tool for assessing candidates developed by Amazon systematically ranked male applicants higher than female ones.(1) Another study of automated ad distribution tools found that gender bias led to the tool more frequently distributing high-paid job offers to men than to women.(2)



**Good judgment(phronesis) is particularly disadvantaged by data-driven methods**

Employers often value good judgment in relation to what their business needs. The good judgment they seek is usually dependent on a particular business context, but the importance of this capacity to make discretionary decisions is rarely explicitly expressed in the data sets. Therefore, it is difficult to apply data-driven matching methods to finding candidates who possess the requisite good judgment. Text analysis tools and data-driven models assume that the meaning of words can be derived directly from their linguistic context. They thus ignore other contexts that are factually relevant.


**The promiscuous use of personal information by recruiters**

Today’s staffing industry collects a wealth of information about job seekers. In addition to CVs and cover letters, different types of personality, intelligence and appraisal tests are often used. Furthermore, it is common to use information about the individual found on the web in the selection process.

The information that is stored is partially limited by the GDPR and by the applicant’s consent. However, questions have been raised as to whether this protection is sufficient, because the job seeker is in a vulnerable situation. By implication, the individual’s consent to the collection of such information is required in order for her/him to be able to get the job.



**Career skills and digital exclusion**

Career skills, including knowledge of the labour market and how recruitment is carried out, are crucial both to finding a suitable job and getting hired. New digital technologies are transforming the recruitment process; matching algorithms, AI, VR, social media, recruitment systems, etc. are increasingly affecting recruitment. This means that knowledge of how these technologies work is important to success in the job search. However, the possibility of accessing relevant knowledge is partly hampered by the problems of what is commonly referred to as algorithmic transparency. Today, most recruitment sites generally lack open information about how their digital matching methods work.



**Unclear responsibility when data-driven models go wrong**

Closely tied to algorithmic transparency is the issue of accountability, so-called algorithmic accountability.(3) A recruitment system that applies machine learning to gradually adjust who gets which job, and what determines who gets which job, rarely has a single-point-of-failure. Therefore, when something goes wrong, responsibility must be distributed among a variety of actors. Who is really responsible when an algorithm-driven decision results in discriminatory or unfair consequences? The law is often not in line with developments, further complicating the issue of accountability. (4)

[Discuss in our discussion forum!](https://forum.jobtechdev.se/t/digital-matchning-vad-kan-val-ga-fel/344)





**References**

1. [https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scrapssecret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scrapssecret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G)
2. Datta, A., Tschantz, M.C., Datta, A. (2015). Automated Experiments on Ad Privacy Settings – A Tale of Opacity, Choice, and Discrimination. Proceedings on Privacy Enhancing Technologies. 1: 92–112, DOI: 10.1515/popets-2015-0007.
3.  Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI, [https://www.sciencedirect.com/science/article/pii/S1566253519308103#fig0005](https://www.sciencedirect.com/science/article/pii/S1566253519308103#fig0005)
4. Hållbar AI. Inventering av kunskapsläget för etiska, sociala och rättsliga utmaningar med artificiell intelligens. Anna Felländer et al. AI Sustainability Center. 2019.

- Algorithms of Oppression: How search engines reinforce racism. Safiya Noble (2018).
- [https://www.forbes.com/sites/tomaspremuzic/2018/05/27/four-unethical-uses-of-ai-in-recruitment/](https://www.forbes.com/sites/tomaspremuzic/2018/05/27/four-unethical-uses-of-ai-in-recruitment/)
- [https://towardsdatascience.com/solving-the-ai-accountability-gap-dd35698249fe](https://towardsdatascience.com/solving-the-ai-accountability-gap-dd35698249fe)
- [https://www.dn.se/ekonomi/det-har-far-rekryterare-gora-med-informationen-du-lamnar/](https://www.dn.se/ekonomi/det-har-far-rekryterare-gora-med-informationen-du-lamnar/)
